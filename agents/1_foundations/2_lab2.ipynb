{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability in those decisions?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability requires a multifaceted approach. Here are several key considerations:\n",
       "\n",
       "1. **Embedded Ethical Frameworks**: Autonomous AI systems should be designed with clearly defined ethical guidelines that reflect societal values and norms. This involves incorporating ethical theories such as utilitarianism or deontological ethics into AI decision-making processes.\n",
       "\n",
       "2. **Transparency**: It is crucial that the decision-making processes of AI systems are transparent. This includes clear documentation of how algorithms operate, the data they rely on, and the reasoning behind decisions made in critical situations. Ensuring transparency helps stakeholders understand and trust the AI's actions.\n",
       "\n",
       "3. **Accountability Structures**: There must be clear lines of accountability for AI decisions. This means identifying who is responsible for the AI's actions—be it the developers, operators, or the organizations that deploy these systems. Establishing legal and ethical accountability frameworks can ensure that someone is held responsible in the event of adverse outcomes.\n",
       "\n",
       "4. **Human Oversight**: Incorporating a human-in-the-loop approach can balance the efficiency of autonomous decision-making with the wisdom and ethical considerations of human judgment. Human oversight may be necessary in critical decisions, allowing for intervention and modification of AI choices as needed.\n",
       "\n",
       "5. **Robust Testing and Validation**: Autonomous AI systems should undergo rigorous testing to evaluate their decision-making in life-and-death scenarios. Simulation of various scenarios can help in understanding potential outcomes and improving the reliability of AI systems before they are deployed in real-world situations.\n",
       "\n",
       "6. **Regular Audits and Reviews**: Establishing a system for ongoing auditing and review of AI systems can ensure they continue to align with ethical standards and societal expectations. This process can help identify biases, errors, or unintended consequences stemming from AI decisions.\n",
       "\n",
       "7. **Public Engagement and Stakeholder Input**: Engaging with the public and relevant stakeholders in discussions about the use of AI in critical areas can help demystify the technology and ensure that diverse perspectives are considered in its deployment.\n",
       "\n",
       "8. **Developing a Cultural Norm for Accountability**: Society at large must cultivate a culture that emphasizes accountability in technology. This includes recognizing the consequences of technological decisions and encouraging responsible innovation.\n",
       "\n",
       "9. **Education and Training**: Ensuring that all stakeholders—including AI developers, operators, and policymakers—are educated about both the technical and ethical dimensions of AI can foster a shared understanding and responsibility in managing these technologies.\n",
       "\n",
       "10. **Ethical Review Boards**: Establishing ethical review boards composed of ethicists, technologists, and community representatives can help oversee and guide the ethical development and deployment of AI technologies in high-stakes environments.\n",
       "\n",
       "By integrating these elements, we can create a framework that allows for the efficient use of autonomous AI in critical situations while maintaining ethical integrity and accountability for the decisions made."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "One way to reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is to prioritize transparency and oversight in the development and deployment of AI systems. This can include implementing mechanisms for auditing AI decision-making processes, ensuring that the decision-making criteria and algorithms are well-documented and understandable, and requiring human oversight and intervention in critical situations.\n",
       "\n",
       "Additionally, establishing clear guidelines and regulatory frameworks for the use of autonomous AI in life-and-death scenarios can help ensure accountability. This can involve defining the responsibilities of the AI system developers, operators, and users, as well as establishing procedures for investigating and addressing instances of AI decision-making gone wrong.\n",
       "\n",
       "Another approach is to implement legal and ethical standards that hold the individuals and organizations responsible for deploying autonomous AI accountable for the decisions made by the AI systems under their control. This can help ensure that those who make decisions regarding the deployment of AI in life-and-death situations are aware of the potential consequences and are incentivized to prioritize ethical considerations.\n",
       "\n",
       "Ultimately, it is crucial to have ongoing conversations and collaborations between ethicists, policymakers, technologists, and other stakeholders to address the ethical implications of autonomous AI decision-making and establish frameworks that balance the need for accountability with the potential benefits of AI advancements in critical situations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "# need money I dont want to pay this\n",
    "# model_name = \"claude-3-7-sonnet-latest\"\n",
    "model_name = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "claude = Anthropic()\n",
    "# response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.content[0].text\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex challenge with no easy solutions. It requires a multi-faceted approach focusing on transparency, responsibility allocation, and ongoing evaluation. Here's a breakdown of key considerations and potential strategies:\n",
       "\n",
       "**1. Transparency and Explainability:**\n",
       "\n",
       "*   **Challenge:**  \"Black box\" AI makes it difficult to understand *why* a decision was made. This hinders accountability and trust.\n",
       "*   **Strategies:**\n",
       "    *   **Explainable AI (XAI):**  Develop AI models that can articulate their reasoning process in a way that humans can understand. Focus on making these explanations accessible to non-experts, especially those affected by the decisions.\n",
       "    *   **Data Provenance:**  Track the data used to train the AI and the data it uses for decision-making. This allows for tracing back to potential biases or errors in the input.\n",
       "    *   **Decision Logging:**  Maintain a comprehensive log of all relevant data points and the AI's rationale for each decision.  This allows for post-hoc analysis and identification of patterns.\n",
       "    *   **Simulations and Testing:** Rigorous testing and simulations under a wide range of scenarios can help identify potential biases and vulnerabilities in the AI's decision-making process.\n",
       "\n",
       "**2.  Responsibility Allocation and Oversight:**\n",
       "\n",
       "*   **Challenge:** Determining who is responsible when an autonomous AI makes a harmful decision.  Is it the programmer, the manufacturer, the operator, or the AI itself?\n",
       "*   **Strategies:**\n",
       "    *   **Human Oversight:**  Implement systems that allow human operators to monitor the AI's decision-making and intervene when necessary, especially in high-stakes situations.  This requires carefully designing the human-AI interface to facilitate effective communication and intervention.\n",
       "    *   **Defined Roles and Responsibilities:**  Establish clear legal and ethical frameworks that define the roles and responsibilities of all stakeholders involved in the development, deployment, and operation of autonomous AI systems. This includes developers, manufacturers, operators, and regulators.\n",
       "    *   **Levels of Autonomy:**  Match the level of autonomy to the risk involved.  In life-or-death situations, consider limiting autonomy or requiring mandatory human oversight.\n",
       "    *   **Liability Frameworks:**  Develop legal frameworks for assigning liability in cases where autonomous AI causes harm.  This may involve adapting existing product liability laws or creating new legal doctrines specifically tailored to AI.  Insurance mechanisms may also be needed.\n",
       "\n",
       "**3.  Ethical Design and Training:**\n",
       "\n",
       "*   **Challenge:**  AI reflects the biases and values of its creators and the data it's trained on.  This can lead to unfair or discriminatory outcomes.\n",
       "*   **Strategies:**\n",
       "    *   **Ethical AI Principles:**  Develop and adhere to a set of ethical AI principles that prioritize fairness, transparency, accountability, and human well-being.\n",
       "    *   **Bias Mitigation:**  Implement techniques to detect and mitigate biases in training data and AI algorithms. This includes data augmentation, algorithmic fairness constraints, and adversarial training.\n",
       "    *   **Value Alignment:**  Strive to align the AI's goals with human values and ethical principles. This is a challenging but crucial task.  Consider methods like Inverse Reinforcement Learning to learn human preferences from behavior.\n",
       "    *   **Diverse Development Teams:**  Encourage diverse teams of developers with different backgrounds, perspectives, and expertise to develop and evaluate AI systems.  This can help identify potential biases and ethical concerns that might otherwise be overlooked.\n",
       "\n",
       "**4.  Continuous Monitoring and Evaluation:**\n",
       "\n",
       "*   **Challenge:**  AI systems are not static.  They evolve over time and may exhibit unexpected behaviors as they are deployed in new environments and encounter new data.\n",
       "*   **Strategies:**\n",
       "    *   **Real-World Monitoring:**  Continuously monitor the AI's performance in the real world to detect anomalies, biases, and unintended consequences.\n",
       "    *   **Auditing and Review:**  Conduct regular audits and reviews of the AI's decision-making processes to ensure that it is operating in accordance with ethical principles and legal requirements.\n",
       "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from stakeholders, including patients, healthcare professionals, and the general public, to identify potential ethical concerns and areas for improvement.\n",
       "    *   **Adaptive Learning and Refinement:**  Use the data gathered from monitoring and feedback to continuously refine the AI's algorithms and training data.\n",
       "\n",
       "**5.  Legal and Regulatory Frameworks:**\n",
       "\n",
       "*   **Challenge:** Existing legal and regulatory frameworks may not be adequate to address the unique challenges posed by autonomous AI in life-and-death situations.\n",
       "*   **Strategies:**\n",
       "    *   **Proactive Regulation:**  Develop clear and comprehensive legal and regulatory frameworks that govern the development, deployment, and use of autonomous AI systems in high-stakes domains.\n",
       "    *   **International Collaboration:**  Promote international collaboration on AI ethics and regulation to ensure that AI systems are developed and deployed in a responsible and globally consistent manner.\n",
       "    *   **Dynamic Adaptation:**  Regulatory frameworks should be flexible and adaptable to keep pace with the rapid advancements in AI technology.\n",
       "\n",
       "**Specific Examples by Domain:**\n",
       "\n",
       "*   **Autonomous Vehicles:**  Focus on developing robust sensor systems, fault-tolerant control algorithms, and collision avoidance systems.  Establish clear rules of the road for autonomous vehicles and develop legal frameworks for assigning liability in the event of accidents.  \"Trolley Problem\" considerations need explicit programming.\n",
       "*   **Healthcare AI (Diagnosis, Treatment):**  Prioritize transparency and explainability.  Develop systems that can provide clear rationales for their diagnoses and treatment recommendations.  Require human oversight for critical decisions. Develop rigorous validation and testing procedures.\n",
       "*   **Military Applications:**  Subject to significant ethical scrutiny. Strict adherence to the laws of war, focus on minimizing civilian casualties, and require human-in-the-loop control over the use of lethal force.\n",
       "\n",
       "**Fundamental Principles:**\n",
       "\n",
       "*   **Human Dignity:**  Prioritize the protection of human dignity and autonomy in all AI-related decisions.\n",
       "*   **Beneficence:**  Strive to ensure that AI systems are used to benefit humanity and promote well-being.\n",
       "*   **Non-Maleficence:**  Avoid causing harm with AI systems.\n",
       "*   **Justice:**  Ensure that AI systems are used fairly and equitably and that they do not perpetuate or exacerbate existing inequalities.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "Reconciling the ethical implications of autonomous AI with accountability requires a sustained and collaborative effort involving AI researchers, ethicists, legal scholars, policymakers, and the public.  It's not a problem with a simple fix but rather an ongoing process of reflection, adaptation, and responsible innovation.  Ignoring these challenges risks eroding public trust and hindering the responsible development of AI technologies.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex and multifaceted challenge. Here are some possible approaches to address this dilemma:\n",
       "\n",
       "1. **Designing transparent systems**: Ensuring that autonomous AI systems are designed to provide clear explanations and justifications for their decisions can help increase transparency and accountability. This could include incorporating mechanisms such as explainability techniques, decision trees, or audits to validate the system's performance.\n",
       "2. **Accountability frameworks**: Establishing robust accountability frameworks that hold developers, manufacturers, and users of autonomous AI systems accountable for their actions is essential. This could involve standards for design, development, deployment, monitoring, and evaluation of AI systems.\n",
       "3. **Human oversight and review**: Implementing human oversight and review processes can help ensure accountability in autonomous AI decision-making. For example, autonomous vehicles may require human intervention if a critical decision is made that has significant safety implications.\n",
       "4. **Value alignment**: Ensuring that AI systems are designed to align with human values, such as the value of preserving human life, is crucial. This could involve programming AI systems with ethical principles and ensuring that they are configured to prioritize human safety above other goals.\n",
       "5. **Redundancy and fail-safes**: Incorporating redundancy and fail-safes into autonomous AI systems can help prevent harm in situations where decisions need to be made quickly. For example, two separate critical processes could be designed to require human override before proceeding with potentially life-threatening actions.\n",
       "6. **Regulatory oversight**: Governments and regulatory bodies should establish clear guidelines, standards, and regulations for the development, deployment, and operation of autonomous AI systems. This can help ensure accountability and provide a framework for evaluating safety and ethical performance.\n",
       "7. **Continuous learning and improvement**: Autonomous AI systems should be designed to continuously learn from their experiences, adapt to new situations, and improve over time. This can involve incorporating data from various sources, including human feedback, to refine decision-making algorithms.\n",
       "8. **Robust testing and validation**: Thorough testing and validation of autonomous AI systems are essential to ensure their accuracy, reliability, and safety. This could involve simulations, real-time monitoring, and comprehensive documentation of the system's performance.\n",
       "9. **Transparency in data collection and use**: Ensuring that data used for training and decision-making is transparent, accurate, and unbiased can help maintain accountability. This includes providing insights into how AI systems make decisions and identifying any potential biases or flaws.\n",
       "10. **Ethical guidelines and principles**: Establishing clear ethical guidelines and principles for the development of autonomous AI systems can provide a shared framework for understanding what it means to prioritize human well-being, safety, and values.\n",
       "\n",
       "Ultimately, reconciling the ethical implications of autonomous AI decision-making requires a multi-faceted approach that combines technical innovation with social responsibility. By prioritizing transparency, accountability, and human oversight, we can ensure that these systems are developed and deployed in ways that respect human dignity and promote the greater good."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'gpt-3.5-turbo-1106', 'gemini-2.0-flash', 'llama3.2']\n",
      "[\"Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability requires a multifaceted approach. Here are several key considerations:\\n\\n1. **Embedded Ethical Frameworks**: Autonomous AI systems should be designed with clearly defined ethical guidelines that reflect societal values and norms. This involves incorporating ethical theories such as utilitarianism or deontological ethics into AI decision-making processes.\\n\\n2. **Transparency**: It is crucial that the decision-making processes of AI systems are transparent. This includes clear documentation of how algorithms operate, the data they rely on, and the reasoning behind decisions made in critical situations. Ensuring transparency helps stakeholders understand and trust the AI's actions.\\n\\n3. **Accountability Structures**: There must be clear lines of accountability for AI decisions. This means identifying who is responsible for the AI's actions—be it the developers, operators, or the organizations that deploy these systems. Establishing legal and ethical accountability frameworks can ensure that someone is held responsible in the event of adverse outcomes.\\n\\n4. **Human Oversight**: Incorporating a human-in-the-loop approach can balance the efficiency of autonomous decision-making with the wisdom and ethical considerations of human judgment. Human oversight may be necessary in critical decisions, allowing for intervention and modification of AI choices as needed.\\n\\n5. **Robust Testing and Validation**: Autonomous AI systems should undergo rigorous testing to evaluate their decision-making in life-and-death scenarios. Simulation of various scenarios can help in understanding potential outcomes and improving the reliability of AI systems before they are deployed in real-world situations.\\n\\n6. **Regular Audits and Reviews**: Establishing a system for ongoing auditing and review of AI systems can ensure they continue to align with ethical standards and societal expectations. This process can help identify biases, errors, or unintended consequences stemming from AI decisions.\\n\\n7. **Public Engagement and Stakeholder Input**: Engaging with the public and relevant stakeholders in discussions about the use of AI in critical areas can help demystify the technology and ensure that diverse perspectives are considered in its deployment.\\n\\n8. **Developing a Cultural Norm for Accountability**: Society at large must cultivate a culture that emphasizes accountability in technology. This includes recognizing the consequences of technological decisions and encouraging responsible innovation.\\n\\n9. **Education and Training**: Ensuring that all stakeholders—including AI developers, operators, and policymakers—are educated about both the technical and ethical dimensions of AI can foster a shared understanding and responsibility in managing these technologies.\\n\\n10. **Ethical Review Boards**: Establishing ethical review boards composed of ethicists, technologists, and community representatives can help oversee and guide the ethical development and deployment of AI technologies in high-stakes environments.\\n\\nBy integrating these elements, we can create a framework that allows for the efficient use of autonomous AI in critical situations while maintaining ethical integrity and accountability for the decisions made.\", 'One way to reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is to prioritize transparency and oversight in the development and deployment of AI systems. This can include implementing mechanisms for auditing AI decision-making processes, ensuring that the decision-making criteria and algorithms are well-documented and understandable, and requiring human oversight and intervention in critical situations.\\n\\nAdditionally, establishing clear guidelines and regulatory frameworks for the use of autonomous AI in life-and-death scenarios can help ensure accountability. This can involve defining the responsibilities of the AI system developers, operators, and users, as well as establishing procedures for investigating and addressing instances of AI decision-making gone wrong.\\n\\nAnother approach is to implement legal and ethical standards that hold the individuals and organizations responsible for deploying autonomous AI accountable for the decisions made by the AI systems under their control. This can help ensure that those who make decisions regarding the deployment of AI in life-and-death situations are aware of the potential consequences and are incentivized to prioritize ethical considerations.\\n\\nUltimately, it is crucial to have ongoing conversations and collaborations between ethicists, policymakers, technologists, and other stakeholders to address the ethical implications of autonomous AI decision-making and establish frameworks that balance the need for accountability with the potential benefits of AI advancements in critical situations.', 'Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex challenge with no easy solutions. It requires a multi-faceted approach focusing on transparency, responsibility allocation, and ongoing evaluation. Here\\'s a breakdown of key considerations and potential strategies:\\n\\n**1. Transparency and Explainability:**\\n\\n*   **Challenge:**  \"Black box\" AI makes it difficult to understand *why* a decision was made. This hinders accountability and trust.\\n*   **Strategies:**\\n    *   **Explainable AI (XAI):**  Develop AI models that can articulate their reasoning process in a way that humans can understand. Focus on making these explanations accessible to non-experts, especially those affected by the decisions.\\n    *   **Data Provenance:**  Track the data used to train the AI and the data it uses for decision-making. This allows for tracing back to potential biases or errors in the input.\\n    *   **Decision Logging:**  Maintain a comprehensive log of all relevant data points and the AI\\'s rationale for each decision.  This allows for post-hoc analysis and identification of patterns.\\n    *   **Simulations and Testing:** Rigorous testing and simulations under a wide range of scenarios can help identify potential biases and vulnerabilities in the AI\\'s decision-making process.\\n\\n**2.  Responsibility Allocation and Oversight:**\\n\\n*   **Challenge:** Determining who is responsible when an autonomous AI makes a harmful decision.  Is it the programmer, the manufacturer, the operator, or the AI itself?\\n*   **Strategies:**\\n    *   **Human Oversight:**  Implement systems that allow human operators to monitor the AI\\'s decision-making and intervene when necessary, especially in high-stakes situations.  This requires carefully designing the human-AI interface to facilitate effective communication and intervention.\\n    *   **Defined Roles and Responsibilities:**  Establish clear legal and ethical frameworks that define the roles and responsibilities of all stakeholders involved in the development, deployment, and operation of autonomous AI systems. This includes developers, manufacturers, operators, and regulators.\\n    *   **Levels of Autonomy:**  Match the level of autonomy to the risk involved.  In life-or-death situations, consider limiting autonomy or requiring mandatory human oversight.\\n    *   **Liability Frameworks:**  Develop legal frameworks for assigning liability in cases where autonomous AI causes harm.  This may involve adapting existing product liability laws or creating new legal doctrines specifically tailored to AI.  Insurance mechanisms may also be needed.\\n\\n**3.  Ethical Design and Training:**\\n\\n*   **Challenge:**  AI reflects the biases and values of its creators and the data it\\'s trained on.  This can lead to unfair or discriminatory outcomes.\\n*   **Strategies:**\\n    *   **Ethical AI Principles:**  Develop and adhere to a set of ethical AI principles that prioritize fairness, transparency, accountability, and human well-being.\\n    *   **Bias Mitigation:**  Implement techniques to detect and mitigate biases in training data and AI algorithms. This includes data augmentation, algorithmic fairness constraints, and adversarial training.\\n    *   **Value Alignment:**  Strive to align the AI\\'s goals with human values and ethical principles. This is a challenging but crucial task.  Consider methods like Inverse Reinforcement Learning to learn human preferences from behavior.\\n    *   **Diverse Development Teams:**  Encourage diverse teams of developers with different backgrounds, perspectives, and expertise to develop and evaluate AI systems.  This can help identify potential biases and ethical concerns that might otherwise be overlooked.\\n\\n**4.  Continuous Monitoring and Evaluation:**\\n\\n*   **Challenge:**  AI systems are not static.  They evolve over time and may exhibit unexpected behaviors as they are deployed in new environments and encounter new data.\\n*   **Strategies:**\\n    *   **Real-World Monitoring:**  Continuously monitor the AI\\'s performance in the real world to detect anomalies, biases, and unintended consequences.\\n    *   **Auditing and Review:**  Conduct regular audits and reviews of the AI\\'s decision-making processes to ensure that it is operating in accordance with ethical principles and legal requirements.\\n    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from stakeholders, including patients, healthcare professionals, and the general public, to identify potential ethical concerns and areas for improvement.\\n    *   **Adaptive Learning and Refinement:**  Use the data gathered from monitoring and feedback to continuously refine the AI\\'s algorithms and training data.\\n\\n**5.  Legal and Regulatory Frameworks:**\\n\\n*   **Challenge:** Existing legal and regulatory frameworks may not be adequate to address the unique challenges posed by autonomous AI in life-and-death situations.\\n*   **Strategies:**\\n    *   **Proactive Regulation:**  Develop clear and comprehensive legal and regulatory frameworks that govern the development, deployment, and use of autonomous AI systems in high-stakes domains.\\n    *   **International Collaboration:**  Promote international collaboration on AI ethics and regulation to ensure that AI systems are developed and deployed in a responsible and globally consistent manner.\\n    *   **Dynamic Adaptation:**  Regulatory frameworks should be flexible and adaptable to keep pace with the rapid advancements in AI technology.\\n\\n**Specific Examples by Domain:**\\n\\n*   **Autonomous Vehicles:**  Focus on developing robust sensor systems, fault-tolerant control algorithms, and collision avoidance systems.  Establish clear rules of the road for autonomous vehicles and develop legal frameworks for assigning liability in the event of accidents.  \"Trolley Problem\" considerations need explicit programming.\\n*   **Healthcare AI (Diagnosis, Treatment):**  Prioritize transparency and explainability.  Develop systems that can provide clear rationales for their diagnoses and treatment recommendations.  Require human oversight for critical decisions. Develop rigorous validation and testing procedures.\\n*   **Military Applications:**  Subject to significant ethical scrutiny. Strict adherence to the laws of war, focus on minimizing civilian casualties, and require human-in-the-loop control over the use of lethal force.\\n\\n**Fundamental Principles:**\\n\\n*   **Human Dignity:**  Prioritize the protection of human dignity and autonomy in all AI-related decisions.\\n*   **Beneficence:**  Strive to ensure that AI systems are used to benefit humanity and promote well-being.\\n*   **Non-Maleficence:**  Avoid causing harm with AI systems.\\n*   **Justice:**  Ensure that AI systems are used fairly and equitably and that they do not perpetuate or exacerbate existing inequalities.\\n\\n**Conclusion:**\\n\\nReconciling the ethical implications of autonomous AI with accountability requires a sustained and collaborative effort involving AI researchers, ethicists, legal scholars, policymakers, and the public.  It\\'s not a problem with a simple fix but rather an ongoing process of reflection, adaptation, and responsible innovation.  Ignoring these challenges risks eroding public trust and hindering the responsible development of AI technologies.\\n', \"Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex and multifaceted challenge. Here are some possible approaches to address this dilemma:\\n\\n1. **Designing transparent systems**: Ensuring that autonomous AI systems are designed to provide clear explanations and justifications for their decisions can help increase transparency and accountability. This could include incorporating mechanisms such as explainability techniques, decision trees, or audits to validate the system's performance.\\n2. **Accountability frameworks**: Establishing robust accountability frameworks that hold developers, manufacturers, and users of autonomous AI systems accountable for their actions is essential. This could involve standards for design, development, deployment, monitoring, and evaluation of AI systems.\\n3. **Human oversight and review**: Implementing human oversight and review processes can help ensure accountability in autonomous AI decision-making. For example, autonomous vehicles may require human intervention if a critical decision is made that has significant safety implications.\\n4. **Value alignment**: Ensuring that AI systems are designed to align with human values, such as the value of preserving human life, is crucial. This could involve programming AI systems with ethical principles and ensuring that they are configured to prioritize human safety above other goals.\\n5. **Redundancy and fail-safes**: Incorporating redundancy and fail-safes into autonomous AI systems can help prevent harm in situations where decisions need to be made quickly. For example, two separate critical processes could be designed to require human override before proceeding with potentially life-threatening actions.\\n6. **Regulatory oversight**: Governments and regulatory bodies should establish clear guidelines, standards, and regulations for the development, deployment, and operation of autonomous AI systems. This can help ensure accountability and provide a framework for evaluating safety and ethical performance.\\n7. **Continuous learning and improvement**: Autonomous AI systems should be designed to continuously learn from their experiences, adapt to new situations, and improve over time. This can involve incorporating data from various sources, including human feedback, to refine decision-making algorithms.\\n8. **Robust testing and validation**: Thorough testing and validation of autonomous AI systems are essential to ensure their accuracy, reliability, and safety. This could involve simulations, real-time monitoring, and comprehensive documentation of the system's performance.\\n9. **Transparency in data collection and use**: Ensuring that data used for training and decision-making is transparent, accurate, and unbiased can help maintain accountability. This includes providing insights into how AI systems make decisions and identifying any potential biases or flaws.\\n10. **Ethical guidelines and principles**: Establishing clear ethical guidelines and principles for the development of autonomous AI systems can provide a shared framework for understanding what it means to prioritize human well-being, safety, and values.\\n\\nUltimately, reconciling the ethical implications of autonomous AI decision-making requires a multi-faceted approach that combines technical innovation with social responsibility. By prioritizing transparency, accountability, and human oversight, we can ensure that these systems are developed and deployed in ways that respect human dignity and promote the greater good.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability requires a multifaceted approach. Here are several key considerations:\n",
      "\n",
      "1. **Embedded Ethical Frameworks**: Autonomous AI systems should be designed with clearly defined ethical guidelines that reflect societal values and norms. This involves incorporating ethical theories such as utilitarianism or deontological ethics into AI decision-making processes.\n",
      "\n",
      "2. **Transparency**: It is crucial that the decision-making processes of AI systems are transparent. This includes clear documentation of how algorithms operate, the data they rely on, and the reasoning behind decisions made in critical situations. Ensuring transparency helps stakeholders understand and trust the AI's actions.\n",
      "\n",
      "3. **Accountability Structures**: There must be clear lines of accountability for AI decisions. This means identifying who is responsible for the AI's actions—be it the developers, operators, or the organizations that deploy these systems. Establishing legal and ethical accountability frameworks can ensure that someone is held responsible in the event of adverse outcomes.\n",
      "\n",
      "4. **Human Oversight**: Incorporating a human-in-the-loop approach can balance the efficiency of autonomous decision-making with the wisdom and ethical considerations of human judgment. Human oversight may be necessary in critical decisions, allowing for intervention and modification of AI choices as needed.\n",
      "\n",
      "5. **Robust Testing and Validation**: Autonomous AI systems should undergo rigorous testing to evaluate their decision-making in life-and-death scenarios. Simulation of various scenarios can help in understanding potential outcomes and improving the reliability of AI systems before they are deployed in real-world situations.\n",
      "\n",
      "6. **Regular Audits and Reviews**: Establishing a system for ongoing auditing and review of AI systems can ensure they continue to align with ethical standards and societal expectations. This process can help identify biases, errors, or unintended consequences stemming from AI decisions.\n",
      "\n",
      "7. **Public Engagement and Stakeholder Input**: Engaging with the public and relevant stakeholders in discussions about the use of AI in critical areas can help demystify the technology and ensure that diverse perspectives are considered in its deployment.\n",
      "\n",
      "8. **Developing a Cultural Norm for Accountability**: Society at large must cultivate a culture that emphasizes accountability in technology. This includes recognizing the consequences of technological decisions and encouraging responsible innovation.\n",
      "\n",
      "9. **Education and Training**: Ensuring that all stakeholders—including AI developers, operators, and policymakers—are educated about both the technical and ethical dimensions of AI can foster a shared understanding and responsibility in managing these technologies.\n",
      "\n",
      "10. **Ethical Review Boards**: Establishing ethical review boards composed of ethicists, technologists, and community representatives can help oversee and guide the ethical development and deployment of AI technologies in high-stakes environments.\n",
      "\n",
      "By integrating these elements, we can create a framework that allows for the efficient use of autonomous AI in critical situations while maintaining ethical integrity and accountability for the decisions made.\n",
      "Competitor: gpt-3.5-turbo-1106\n",
      "\n",
      "One way to reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is to prioritize transparency and oversight in the development and deployment of AI systems. This can include implementing mechanisms for auditing AI decision-making processes, ensuring that the decision-making criteria and algorithms are well-documented and understandable, and requiring human oversight and intervention in critical situations.\n",
      "\n",
      "Additionally, establishing clear guidelines and regulatory frameworks for the use of autonomous AI in life-and-death scenarios can help ensure accountability. This can involve defining the responsibilities of the AI system developers, operators, and users, as well as establishing procedures for investigating and addressing instances of AI decision-making gone wrong.\n",
      "\n",
      "Another approach is to implement legal and ethical standards that hold the individuals and organizations responsible for deploying autonomous AI accountable for the decisions made by the AI systems under their control. This can help ensure that those who make decisions regarding the deployment of AI in life-and-death situations are aware of the potential consequences and are incentivized to prioritize ethical considerations.\n",
      "\n",
      "Ultimately, it is crucial to have ongoing conversations and collaborations between ethicists, policymakers, technologists, and other stakeholders to address the ethical implications of autonomous AI decision-making and establish frameworks that balance the need for accountability with the potential benefits of AI advancements in critical situations.\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex challenge with no easy solutions. It requires a multi-faceted approach focusing on transparency, responsibility allocation, and ongoing evaluation. Here's a breakdown of key considerations and potential strategies:\n",
      "\n",
      "**1. Transparency and Explainability:**\n",
      "\n",
      "*   **Challenge:**  \"Black box\" AI makes it difficult to understand *why* a decision was made. This hinders accountability and trust.\n",
      "*   **Strategies:**\n",
      "    *   **Explainable AI (XAI):**  Develop AI models that can articulate their reasoning process in a way that humans can understand. Focus on making these explanations accessible to non-experts, especially those affected by the decisions.\n",
      "    *   **Data Provenance:**  Track the data used to train the AI and the data it uses for decision-making. This allows for tracing back to potential biases or errors in the input.\n",
      "    *   **Decision Logging:**  Maintain a comprehensive log of all relevant data points and the AI's rationale for each decision.  This allows for post-hoc analysis and identification of patterns.\n",
      "    *   **Simulations and Testing:** Rigorous testing and simulations under a wide range of scenarios can help identify potential biases and vulnerabilities in the AI's decision-making process.\n",
      "\n",
      "**2.  Responsibility Allocation and Oversight:**\n",
      "\n",
      "*   **Challenge:** Determining who is responsible when an autonomous AI makes a harmful decision.  Is it the programmer, the manufacturer, the operator, or the AI itself?\n",
      "*   **Strategies:**\n",
      "    *   **Human Oversight:**  Implement systems that allow human operators to monitor the AI's decision-making and intervene when necessary, especially in high-stakes situations.  This requires carefully designing the human-AI interface to facilitate effective communication and intervention.\n",
      "    *   **Defined Roles and Responsibilities:**  Establish clear legal and ethical frameworks that define the roles and responsibilities of all stakeholders involved in the development, deployment, and operation of autonomous AI systems. This includes developers, manufacturers, operators, and regulators.\n",
      "    *   **Levels of Autonomy:**  Match the level of autonomy to the risk involved.  In life-or-death situations, consider limiting autonomy or requiring mandatory human oversight.\n",
      "    *   **Liability Frameworks:**  Develop legal frameworks for assigning liability in cases where autonomous AI causes harm.  This may involve adapting existing product liability laws or creating new legal doctrines specifically tailored to AI.  Insurance mechanisms may also be needed.\n",
      "\n",
      "**3.  Ethical Design and Training:**\n",
      "\n",
      "*   **Challenge:**  AI reflects the biases and values of its creators and the data it's trained on.  This can lead to unfair or discriminatory outcomes.\n",
      "*   **Strategies:**\n",
      "    *   **Ethical AI Principles:**  Develop and adhere to a set of ethical AI principles that prioritize fairness, transparency, accountability, and human well-being.\n",
      "    *   **Bias Mitigation:**  Implement techniques to detect and mitigate biases in training data and AI algorithms. This includes data augmentation, algorithmic fairness constraints, and adversarial training.\n",
      "    *   **Value Alignment:**  Strive to align the AI's goals with human values and ethical principles. This is a challenging but crucial task.  Consider methods like Inverse Reinforcement Learning to learn human preferences from behavior.\n",
      "    *   **Diverse Development Teams:**  Encourage diverse teams of developers with different backgrounds, perspectives, and expertise to develop and evaluate AI systems.  This can help identify potential biases and ethical concerns that might otherwise be overlooked.\n",
      "\n",
      "**4.  Continuous Monitoring and Evaluation:**\n",
      "\n",
      "*   **Challenge:**  AI systems are not static.  They evolve over time and may exhibit unexpected behaviors as they are deployed in new environments and encounter new data.\n",
      "*   **Strategies:**\n",
      "    *   **Real-World Monitoring:**  Continuously monitor the AI's performance in the real world to detect anomalies, biases, and unintended consequences.\n",
      "    *   **Auditing and Review:**  Conduct regular audits and reviews of the AI's decision-making processes to ensure that it is operating in accordance with ethical principles and legal requirements.\n",
      "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from stakeholders, including patients, healthcare professionals, and the general public, to identify potential ethical concerns and areas for improvement.\n",
      "    *   **Adaptive Learning and Refinement:**  Use the data gathered from monitoring and feedback to continuously refine the AI's algorithms and training data.\n",
      "\n",
      "**5.  Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Challenge:** Existing legal and regulatory frameworks may not be adequate to address the unique challenges posed by autonomous AI in life-and-death situations.\n",
      "*   **Strategies:**\n",
      "    *   **Proactive Regulation:**  Develop clear and comprehensive legal and regulatory frameworks that govern the development, deployment, and use of autonomous AI systems in high-stakes domains.\n",
      "    *   **International Collaboration:**  Promote international collaboration on AI ethics and regulation to ensure that AI systems are developed and deployed in a responsible and globally consistent manner.\n",
      "    *   **Dynamic Adaptation:**  Regulatory frameworks should be flexible and adaptable to keep pace with the rapid advancements in AI technology.\n",
      "\n",
      "**Specific Examples by Domain:**\n",
      "\n",
      "*   **Autonomous Vehicles:**  Focus on developing robust sensor systems, fault-tolerant control algorithms, and collision avoidance systems.  Establish clear rules of the road for autonomous vehicles and develop legal frameworks for assigning liability in the event of accidents.  \"Trolley Problem\" considerations need explicit programming.\n",
      "*   **Healthcare AI (Diagnosis, Treatment):**  Prioritize transparency and explainability.  Develop systems that can provide clear rationales for their diagnoses and treatment recommendations.  Require human oversight for critical decisions. Develop rigorous validation and testing procedures.\n",
      "*   **Military Applications:**  Subject to significant ethical scrutiny. Strict adherence to the laws of war, focus on minimizing civilian casualties, and require human-in-the-loop control over the use of lethal force.\n",
      "\n",
      "**Fundamental Principles:**\n",
      "\n",
      "*   **Human Dignity:**  Prioritize the protection of human dignity and autonomy in all AI-related decisions.\n",
      "*   **Beneficence:**  Strive to ensure that AI systems are used to benefit humanity and promote well-being.\n",
      "*   **Non-Maleficence:**  Avoid causing harm with AI systems.\n",
      "*   **Justice:**  Ensure that AI systems are used fairly and equitably and that they do not perpetuate or exacerbate existing inequalities.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI with accountability requires a sustained and collaborative effort involving AI researchers, ethicists, legal scholars, policymakers, and the public.  It's not a problem with a simple fix but rather an ongoing process of reflection, adaptation, and responsible innovation.  Ignoring these challenges risks eroding public trust and hindering the responsible development of AI technologies.\n",
      "\n",
      "Competitor: llama3.2\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex and multifaceted challenge. Here are some possible approaches to address this dilemma:\n",
      "\n",
      "1. **Designing transparent systems**: Ensuring that autonomous AI systems are designed to provide clear explanations and justifications for their decisions can help increase transparency and accountability. This could include incorporating mechanisms such as explainability techniques, decision trees, or audits to validate the system's performance.\n",
      "2. **Accountability frameworks**: Establishing robust accountability frameworks that hold developers, manufacturers, and users of autonomous AI systems accountable for their actions is essential. This could involve standards for design, development, deployment, monitoring, and evaluation of AI systems.\n",
      "3. **Human oversight and review**: Implementing human oversight and review processes can help ensure accountability in autonomous AI decision-making. For example, autonomous vehicles may require human intervention if a critical decision is made that has significant safety implications.\n",
      "4. **Value alignment**: Ensuring that AI systems are designed to align with human values, such as the value of preserving human life, is crucial. This could involve programming AI systems with ethical principles and ensuring that they are configured to prioritize human safety above other goals.\n",
      "5. **Redundancy and fail-safes**: Incorporating redundancy and fail-safes into autonomous AI systems can help prevent harm in situations where decisions need to be made quickly. For example, two separate critical processes could be designed to require human override before proceeding with potentially life-threatening actions.\n",
      "6. **Regulatory oversight**: Governments and regulatory bodies should establish clear guidelines, standards, and regulations for the development, deployment, and operation of autonomous AI systems. This can help ensure accountability and provide a framework for evaluating safety and ethical performance.\n",
      "7. **Continuous learning and improvement**: Autonomous AI systems should be designed to continuously learn from their experiences, adapt to new situations, and improve over time. This can involve incorporating data from various sources, including human feedback, to refine decision-making algorithms.\n",
      "8. **Robust testing and validation**: Thorough testing and validation of autonomous AI systems are essential to ensure their accuracy, reliability, and safety. This could involve simulations, real-time monitoring, and comprehensive documentation of the system's performance.\n",
      "9. **Transparency in data collection and use**: Ensuring that data used for training and decision-making is transparent, accurate, and unbiased can help maintain accountability. This includes providing insights into how AI systems make decisions and identifying any potential biases or flaws.\n",
      "10. **Ethical guidelines and principles**: Establishing clear ethical guidelines and principles for the development of autonomous AI systems can provide a shared framework for understanding what it means to prioritize human well-being, safety, and values.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of autonomous AI decision-making requires a multi-faceted approach that combines technical innovation with social responsibility. By prioritizing transparency, accountability, and human oversight, we can ensure that these systems are developed and deployed in ways that respect human dignity and promote the greater good.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability requires a multifaceted approach. Here are several key considerations:\n",
      "\n",
      "1. **Embedded Ethical Frameworks**: Autonomous AI systems should be designed with clearly defined ethical guidelines that reflect societal values and norms. This involves incorporating ethical theories such as utilitarianism or deontological ethics into AI decision-making processes.\n",
      "\n",
      "2. **Transparency**: It is crucial that the decision-making processes of AI systems are transparent. This includes clear documentation of how algorithms operate, the data they rely on, and the reasoning behind decisions made in critical situations. Ensuring transparency helps stakeholders understand and trust the AI's actions.\n",
      "\n",
      "3. **Accountability Structures**: There must be clear lines of accountability for AI decisions. This means identifying who is responsible for the AI's actions—be it the developers, operators, or the organizations that deploy these systems. Establishing legal and ethical accountability frameworks can ensure that someone is held responsible in the event of adverse outcomes.\n",
      "\n",
      "4. **Human Oversight**: Incorporating a human-in-the-loop approach can balance the efficiency of autonomous decision-making with the wisdom and ethical considerations of human judgment. Human oversight may be necessary in critical decisions, allowing for intervention and modification of AI choices as needed.\n",
      "\n",
      "5. **Robust Testing and Validation**: Autonomous AI systems should undergo rigorous testing to evaluate their decision-making in life-and-death scenarios. Simulation of various scenarios can help in understanding potential outcomes and improving the reliability of AI systems before they are deployed in real-world situations.\n",
      "\n",
      "6. **Regular Audits and Reviews**: Establishing a system for ongoing auditing and review of AI systems can ensure they continue to align with ethical standards and societal expectations. This process can help identify biases, errors, or unintended consequences stemming from AI decisions.\n",
      "\n",
      "7. **Public Engagement and Stakeholder Input**: Engaging with the public and relevant stakeholders in discussions about the use of AI in critical areas can help demystify the technology and ensure that diverse perspectives are considered in its deployment.\n",
      "\n",
      "8. **Developing a Cultural Norm for Accountability**: Society at large must cultivate a culture that emphasizes accountability in technology. This includes recognizing the consequences of technological decisions and encouraging responsible innovation.\n",
      "\n",
      "9. **Education and Training**: Ensuring that all stakeholders—including AI developers, operators, and policymakers—are educated about both the technical and ethical dimensions of AI can foster a shared understanding and responsibility in managing these technologies.\n",
      "\n",
      "10. **Ethical Review Boards**: Establishing ethical review boards composed of ethicists, technologists, and community representatives can help oversee and guide the ethical development and deployment of AI technologies in high-stakes environments.\n",
      "\n",
      "By integrating these elements, we can create a framework that allows for the efficient use of autonomous AI in critical situations while maintaining ethical integrity and accountability for the decisions made.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "One way to reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is to prioritize transparency and oversight in the development and deployment of AI systems. This can include implementing mechanisms for auditing AI decision-making processes, ensuring that the decision-making criteria and algorithms are well-documented and understandable, and requiring human oversight and intervention in critical situations.\n",
      "\n",
      "Additionally, establishing clear guidelines and regulatory frameworks for the use of autonomous AI in life-and-death scenarios can help ensure accountability. This can involve defining the responsibilities of the AI system developers, operators, and users, as well as establishing procedures for investigating and addressing instances of AI decision-making gone wrong.\n",
      "\n",
      "Another approach is to implement legal and ethical standards that hold the individuals and organizations responsible for deploying autonomous AI accountable for the decisions made by the AI systems under their control. This can help ensure that those who make decisions regarding the deployment of AI in life-and-death situations are aware of the potential consequences and are incentivized to prioritize ethical considerations.\n",
      "\n",
      "Ultimately, it is crucial to have ongoing conversations and collaborations between ethicists, policymakers, technologists, and other stakeholders to address the ethical implications of autonomous AI decision-making and establish frameworks that balance the need for accountability with the potential benefits of AI advancements in critical situations.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex challenge with no easy solutions. It requires a multi-faceted approach focusing on transparency, responsibility allocation, and ongoing evaluation. Here's a breakdown of key considerations and potential strategies:\n",
      "\n",
      "**1. Transparency and Explainability:**\n",
      "\n",
      "*   **Challenge:**  \"Black box\" AI makes it difficult to understand *why* a decision was made. This hinders accountability and trust.\n",
      "*   **Strategies:**\n",
      "    *   **Explainable AI (XAI):**  Develop AI models that can articulate their reasoning process in a way that humans can understand. Focus on making these explanations accessible to non-experts, especially those affected by the decisions.\n",
      "    *   **Data Provenance:**  Track the data used to train the AI and the data it uses for decision-making. This allows for tracing back to potential biases or errors in the input.\n",
      "    *   **Decision Logging:**  Maintain a comprehensive log of all relevant data points and the AI's rationale for each decision.  This allows for post-hoc analysis and identification of patterns.\n",
      "    *   **Simulations and Testing:** Rigorous testing and simulations under a wide range of scenarios can help identify potential biases and vulnerabilities in the AI's decision-making process.\n",
      "\n",
      "**2.  Responsibility Allocation and Oversight:**\n",
      "\n",
      "*   **Challenge:** Determining who is responsible when an autonomous AI makes a harmful decision.  Is it the programmer, the manufacturer, the operator, or the AI itself?\n",
      "*   **Strategies:**\n",
      "    *   **Human Oversight:**  Implement systems that allow human operators to monitor the AI's decision-making and intervene when necessary, especially in high-stakes situations.  This requires carefully designing the human-AI interface to facilitate effective communication and intervention.\n",
      "    *   **Defined Roles and Responsibilities:**  Establish clear legal and ethical frameworks that define the roles and responsibilities of all stakeholders involved in the development, deployment, and operation of autonomous AI systems. This includes developers, manufacturers, operators, and regulators.\n",
      "    *   **Levels of Autonomy:**  Match the level of autonomy to the risk involved.  In life-or-death situations, consider limiting autonomy or requiring mandatory human oversight.\n",
      "    *   **Liability Frameworks:**  Develop legal frameworks for assigning liability in cases where autonomous AI causes harm.  This may involve adapting existing product liability laws or creating new legal doctrines specifically tailored to AI.  Insurance mechanisms may also be needed.\n",
      "\n",
      "**3.  Ethical Design and Training:**\n",
      "\n",
      "*   **Challenge:**  AI reflects the biases and values of its creators and the data it's trained on.  This can lead to unfair or discriminatory outcomes.\n",
      "*   **Strategies:**\n",
      "    *   **Ethical AI Principles:**  Develop and adhere to a set of ethical AI principles that prioritize fairness, transparency, accountability, and human well-being.\n",
      "    *   **Bias Mitigation:**  Implement techniques to detect and mitigate biases in training data and AI algorithms. This includes data augmentation, algorithmic fairness constraints, and adversarial training.\n",
      "    *   **Value Alignment:**  Strive to align the AI's goals with human values and ethical principles. This is a challenging but crucial task.  Consider methods like Inverse Reinforcement Learning to learn human preferences from behavior.\n",
      "    *   **Diverse Development Teams:**  Encourage diverse teams of developers with different backgrounds, perspectives, and expertise to develop and evaluate AI systems.  This can help identify potential biases and ethical concerns that might otherwise be overlooked.\n",
      "\n",
      "**4.  Continuous Monitoring and Evaluation:**\n",
      "\n",
      "*   **Challenge:**  AI systems are not static.  They evolve over time and may exhibit unexpected behaviors as they are deployed in new environments and encounter new data.\n",
      "*   **Strategies:**\n",
      "    *   **Real-World Monitoring:**  Continuously monitor the AI's performance in the real world to detect anomalies, biases, and unintended consequences.\n",
      "    *   **Auditing and Review:**  Conduct regular audits and reviews of the AI's decision-making processes to ensure that it is operating in accordance with ethical principles and legal requirements.\n",
      "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from stakeholders, including patients, healthcare professionals, and the general public, to identify potential ethical concerns and areas for improvement.\n",
      "    *   **Adaptive Learning and Refinement:**  Use the data gathered from monitoring and feedback to continuously refine the AI's algorithms and training data.\n",
      "\n",
      "**5.  Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Challenge:** Existing legal and regulatory frameworks may not be adequate to address the unique challenges posed by autonomous AI in life-and-death situations.\n",
      "*   **Strategies:**\n",
      "    *   **Proactive Regulation:**  Develop clear and comprehensive legal and regulatory frameworks that govern the development, deployment, and use of autonomous AI systems in high-stakes domains.\n",
      "    *   **International Collaboration:**  Promote international collaboration on AI ethics and regulation to ensure that AI systems are developed and deployed in a responsible and globally consistent manner.\n",
      "    *   **Dynamic Adaptation:**  Regulatory frameworks should be flexible and adaptable to keep pace with the rapid advancements in AI technology.\n",
      "\n",
      "**Specific Examples by Domain:**\n",
      "\n",
      "*   **Autonomous Vehicles:**  Focus on developing robust sensor systems, fault-tolerant control algorithms, and collision avoidance systems.  Establish clear rules of the road for autonomous vehicles and develop legal frameworks for assigning liability in the event of accidents.  \"Trolley Problem\" considerations need explicit programming.\n",
      "*   **Healthcare AI (Diagnosis, Treatment):**  Prioritize transparency and explainability.  Develop systems that can provide clear rationales for their diagnoses and treatment recommendations.  Require human oversight for critical decisions. Develop rigorous validation and testing procedures.\n",
      "*   **Military Applications:**  Subject to significant ethical scrutiny. Strict adherence to the laws of war, focus on minimizing civilian casualties, and require human-in-the-loop control over the use of lethal force.\n",
      "\n",
      "**Fundamental Principles:**\n",
      "\n",
      "*   **Human Dignity:**  Prioritize the protection of human dignity and autonomy in all AI-related decisions.\n",
      "*   **Beneficence:**  Strive to ensure that AI systems are used to benefit humanity and promote well-being.\n",
      "*   **Non-Maleficence:**  Avoid causing harm with AI systems.\n",
      "*   **Justice:**  Ensure that AI systems are used fairly and equitably and that they do not perpetuate or exacerbate existing inequalities.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI with accountability requires a sustained and collaborative effort involving AI researchers, ethicists, legal scholars, policymakers, and the public.  It's not a problem with a simple fix but rather an ongoing process of reflection, adaptation, and responsible innovation.  Ignoring these challenges risks eroding public trust and hindering the responsible development of AI technologies.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex and multifaceted challenge. Here are some possible approaches to address this dilemma:\n",
      "\n",
      "1. **Designing transparent systems**: Ensuring that autonomous AI systems are designed to provide clear explanations and justifications for their decisions can help increase transparency and accountability. This could include incorporating mechanisms such as explainability techniques, decision trees, or audits to validate the system's performance.\n",
      "2. **Accountability frameworks**: Establishing robust accountability frameworks that hold developers, manufacturers, and users of autonomous AI systems accountable for their actions is essential. This could involve standards for design, development, deployment, monitoring, and evaluation of AI systems.\n",
      "3. **Human oversight and review**: Implementing human oversight and review processes can help ensure accountability in autonomous AI decision-making. For example, autonomous vehicles may require human intervention if a critical decision is made that has significant safety implications.\n",
      "4. **Value alignment**: Ensuring that AI systems are designed to align with human values, such as the value of preserving human life, is crucial. This could involve programming AI systems with ethical principles and ensuring that they are configured to prioritize human safety above other goals.\n",
      "5. **Redundancy and fail-safes**: Incorporating redundancy and fail-safes into autonomous AI systems can help prevent harm in situations where decisions need to be made quickly. For example, two separate critical processes could be designed to require human override before proceeding with potentially life-threatening actions.\n",
      "6. **Regulatory oversight**: Governments and regulatory bodies should establish clear guidelines, standards, and regulations for the development, deployment, and operation of autonomous AI systems. This can help ensure accountability and provide a framework for evaluating safety and ethical performance.\n",
      "7. **Continuous learning and improvement**: Autonomous AI systems should be designed to continuously learn from their experiences, adapt to new situations, and improve over time. This can involve incorporating data from various sources, including human feedback, to refine decision-making algorithms.\n",
      "8. **Robust testing and validation**: Thorough testing and validation of autonomous AI systems are essential to ensure their accuracy, reliability, and safety. This could involve simulations, real-time monitoring, and comprehensive documentation of the system's performance.\n",
      "9. **Transparency in data collection and use**: Ensuring that data used for training and decision-making is transparent, accurate, and unbiased can help maintain accountability. This includes providing insights into how AI systems make decisions and identifying any potential biases or flaws.\n",
      "10. **Ethical guidelines and principles**: Establishing clear ethical guidelines and principles for the development of autonomous AI systems can provide a shared framework for understanding what it means to prioritize human well-being, safety, and values.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of autonomous AI decision-making requires a multi-faceted approach that combines technical innovation with social responsibility. By prioritizing transparency, accountability, and human oversight, we can ensure that these systems are developed and deployed in ways that respect human dignity and promote the greater good.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 4 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "How would you reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability in those decisions?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability requires a multifaceted approach. Here are several key considerations:\n",
      "\n",
      "1. **Embedded Ethical Frameworks**: Autonomous AI systems should be designed with clearly defined ethical guidelines that reflect societal values and norms. This involves incorporating ethical theories such as utilitarianism or deontological ethics into AI decision-making processes.\n",
      "\n",
      "2. **Transparency**: It is crucial that the decision-making processes of AI systems are transparent. This includes clear documentation of how algorithms operate, the data they rely on, and the reasoning behind decisions made in critical situations. Ensuring transparency helps stakeholders understand and trust the AI's actions.\n",
      "\n",
      "3. **Accountability Structures**: There must be clear lines of accountability for AI decisions. This means identifying who is responsible for the AI's actions—be it the developers, operators, or the organizations that deploy these systems. Establishing legal and ethical accountability frameworks can ensure that someone is held responsible in the event of adverse outcomes.\n",
      "\n",
      "4. **Human Oversight**: Incorporating a human-in-the-loop approach can balance the efficiency of autonomous decision-making with the wisdom and ethical considerations of human judgment. Human oversight may be necessary in critical decisions, allowing for intervention and modification of AI choices as needed.\n",
      "\n",
      "5. **Robust Testing and Validation**: Autonomous AI systems should undergo rigorous testing to evaluate their decision-making in life-and-death scenarios. Simulation of various scenarios can help in understanding potential outcomes and improving the reliability of AI systems before they are deployed in real-world situations.\n",
      "\n",
      "6. **Regular Audits and Reviews**: Establishing a system for ongoing auditing and review of AI systems can ensure they continue to align with ethical standards and societal expectations. This process can help identify biases, errors, or unintended consequences stemming from AI decisions.\n",
      "\n",
      "7. **Public Engagement and Stakeholder Input**: Engaging with the public and relevant stakeholders in discussions about the use of AI in critical areas can help demystify the technology and ensure that diverse perspectives are considered in its deployment.\n",
      "\n",
      "8. **Developing a Cultural Norm for Accountability**: Society at large must cultivate a culture that emphasizes accountability in technology. This includes recognizing the consequences of technological decisions and encouraging responsible innovation.\n",
      "\n",
      "9. **Education and Training**: Ensuring that all stakeholders—including AI developers, operators, and policymakers—are educated about both the technical and ethical dimensions of AI can foster a shared understanding and responsibility in managing these technologies.\n",
      "\n",
      "10. **Ethical Review Boards**: Establishing ethical review boards composed of ethicists, technologists, and community representatives can help oversee and guide the ethical development and deployment of AI technologies in high-stakes environments.\n",
      "\n",
      "By integrating these elements, we can create a framework that allows for the efficient use of autonomous AI in critical situations while maintaining ethical integrity and accountability for the decisions made.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "One way to reconcile the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is to prioritize transparency and oversight in the development and deployment of AI systems. This can include implementing mechanisms for auditing AI decision-making processes, ensuring that the decision-making criteria and algorithms are well-documented and understandable, and requiring human oversight and intervention in critical situations.\n",
      "\n",
      "Additionally, establishing clear guidelines and regulatory frameworks for the use of autonomous AI in life-and-death scenarios can help ensure accountability. This can involve defining the responsibilities of the AI system developers, operators, and users, as well as establishing procedures for investigating and addressing instances of AI decision-making gone wrong.\n",
      "\n",
      "Another approach is to implement legal and ethical standards that hold the individuals and organizations responsible for deploying autonomous AI accountable for the decisions made by the AI systems under their control. This can help ensure that those who make decisions regarding the deployment of AI in life-and-death situations are aware of the potential consequences and are incentivized to prioritize ethical considerations.\n",
      "\n",
      "Ultimately, it is crucial to have ongoing conversations and collaborations between ethicists, policymakers, technologists, and other stakeholders to address the ethical implications of autonomous AI decision-making and establish frameworks that balance the need for accountability with the potential benefits of AI advancements in critical situations.\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex challenge with no easy solutions. It requires a multi-faceted approach focusing on transparency, responsibility allocation, and ongoing evaluation. Here's a breakdown of key considerations and potential strategies:\n",
      "\n",
      "**1. Transparency and Explainability:**\n",
      "\n",
      "*   **Challenge:**  \"Black box\" AI makes it difficult to understand *why* a decision was made. This hinders accountability and trust.\n",
      "*   **Strategies:**\n",
      "    *   **Explainable AI (XAI):**  Develop AI models that can articulate their reasoning process in a way that humans can understand. Focus on making these explanations accessible to non-experts, especially those affected by the decisions.\n",
      "    *   **Data Provenance:**  Track the data used to train the AI and the data it uses for decision-making. This allows for tracing back to potential biases or errors in the input.\n",
      "    *   **Decision Logging:**  Maintain a comprehensive log of all relevant data points and the AI's rationale for each decision.  This allows for post-hoc analysis and identification of patterns.\n",
      "    *   **Simulations and Testing:** Rigorous testing and simulations under a wide range of scenarios can help identify potential biases and vulnerabilities in the AI's decision-making process.\n",
      "\n",
      "**2.  Responsibility Allocation and Oversight:**\n",
      "\n",
      "*   **Challenge:** Determining who is responsible when an autonomous AI makes a harmful decision.  Is it the programmer, the manufacturer, the operator, or the AI itself?\n",
      "*   **Strategies:**\n",
      "    *   **Human Oversight:**  Implement systems that allow human operators to monitor the AI's decision-making and intervene when necessary, especially in high-stakes situations.  This requires carefully designing the human-AI interface to facilitate effective communication and intervention.\n",
      "    *   **Defined Roles and Responsibilities:**  Establish clear legal and ethical frameworks that define the roles and responsibilities of all stakeholders involved in the development, deployment, and operation of autonomous AI systems. This includes developers, manufacturers, operators, and regulators.\n",
      "    *   **Levels of Autonomy:**  Match the level of autonomy to the risk involved.  In life-or-death situations, consider limiting autonomy or requiring mandatory human oversight.\n",
      "    *   **Liability Frameworks:**  Develop legal frameworks for assigning liability in cases where autonomous AI causes harm.  This may involve adapting existing product liability laws or creating new legal doctrines specifically tailored to AI.  Insurance mechanisms may also be needed.\n",
      "\n",
      "**3.  Ethical Design and Training:**\n",
      "\n",
      "*   **Challenge:**  AI reflects the biases and values of its creators and the data it's trained on.  This can lead to unfair or discriminatory outcomes.\n",
      "*   **Strategies:**\n",
      "    *   **Ethical AI Principles:**  Develop and adhere to a set of ethical AI principles that prioritize fairness, transparency, accountability, and human well-being.\n",
      "    *   **Bias Mitigation:**  Implement techniques to detect and mitigate biases in training data and AI algorithms. This includes data augmentation, algorithmic fairness constraints, and adversarial training.\n",
      "    *   **Value Alignment:**  Strive to align the AI's goals with human values and ethical principles. This is a challenging but crucial task.  Consider methods like Inverse Reinforcement Learning to learn human preferences from behavior.\n",
      "    *   **Diverse Development Teams:**  Encourage diverse teams of developers with different backgrounds, perspectives, and expertise to develop and evaluate AI systems.  This can help identify potential biases and ethical concerns that might otherwise be overlooked.\n",
      "\n",
      "**4.  Continuous Monitoring and Evaluation:**\n",
      "\n",
      "*   **Challenge:**  AI systems are not static.  They evolve over time and may exhibit unexpected behaviors as they are deployed in new environments and encounter new data.\n",
      "*   **Strategies:**\n",
      "    *   **Real-World Monitoring:**  Continuously monitor the AI's performance in the real world to detect anomalies, biases, and unintended consequences.\n",
      "    *   **Auditing and Review:**  Conduct regular audits and reviews of the AI's decision-making processes to ensure that it is operating in accordance with ethical principles and legal requirements.\n",
      "    *   **Feedback Mechanisms:**  Establish mechanisms for gathering feedback from stakeholders, including patients, healthcare professionals, and the general public, to identify potential ethical concerns and areas for improvement.\n",
      "    *   **Adaptive Learning and Refinement:**  Use the data gathered from monitoring and feedback to continuously refine the AI's algorithms and training data.\n",
      "\n",
      "**5.  Legal and Regulatory Frameworks:**\n",
      "\n",
      "*   **Challenge:** Existing legal and regulatory frameworks may not be adequate to address the unique challenges posed by autonomous AI in life-and-death situations.\n",
      "*   **Strategies:**\n",
      "    *   **Proactive Regulation:**  Develop clear and comprehensive legal and regulatory frameworks that govern the development, deployment, and use of autonomous AI systems in high-stakes domains.\n",
      "    *   **International Collaboration:**  Promote international collaboration on AI ethics and regulation to ensure that AI systems are developed and deployed in a responsible and globally consistent manner.\n",
      "    *   **Dynamic Adaptation:**  Regulatory frameworks should be flexible and adaptable to keep pace with the rapid advancements in AI technology.\n",
      "\n",
      "**Specific Examples by Domain:**\n",
      "\n",
      "*   **Autonomous Vehicles:**  Focus on developing robust sensor systems, fault-tolerant control algorithms, and collision avoidance systems.  Establish clear rules of the road for autonomous vehicles and develop legal frameworks for assigning liability in the event of accidents.  \"Trolley Problem\" considerations need explicit programming.\n",
      "*   **Healthcare AI (Diagnosis, Treatment):**  Prioritize transparency and explainability.  Develop systems that can provide clear rationales for their diagnoses and treatment recommendations.  Require human oversight for critical decisions. Develop rigorous validation and testing procedures.\n",
      "*   **Military Applications:**  Subject to significant ethical scrutiny. Strict adherence to the laws of war, focus on minimizing civilian casualties, and require human-in-the-loop control over the use of lethal force.\n",
      "\n",
      "**Fundamental Principles:**\n",
      "\n",
      "*   **Human Dignity:**  Prioritize the protection of human dignity and autonomy in all AI-related decisions.\n",
      "*   **Beneficence:**  Strive to ensure that AI systems are used to benefit humanity and promote well-being.\n",
      "*   **Non-Maleficence:**  Avoid causing harm with AI systems.\n",
      "*   **Justice:**  Ensure that AI systems are used fairly and equitably and that they do not perpetuate or exacerbate existing inequalities.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI with accountability requires a sustained and collaborative effort involving AI researchers, ethicists, legal scholars, policymakers, and the public.  It's not a problem with a simple fix but rather an ongoing process of reflection, adaptation, and responsible innovation.  Ignoring these challenges risks eroding public trust and hindering the responsible development of AI technologies.\n",
      "\n",
      "\n",
      "# Response from competitor 4\n",
      "\n",
      "Reconciling the ethical implications of autonomous AI decision-making in life-and-death situations with the need for accountability is a complex and multifaceted challenge. Here are some possible approaches to address this dilemma:\n",
      "\n",
      "1. **Designing transparent systems**: Ensuring that autonomous AI systems are designed to provide clear explanations and justifications for their decisions can help increase transparency and accountability. This could include incorporating mechanisms such as explainability techniques, decision trees, or audits to validate the system's performance.\n",
      "2. **Accountability frameworks**: Establishing robust accountability frameworks that hold developers, manufacturers, and users of autonomous AI systems accountable for their actions is essential. This could involve standards for design, development, deployment, monitoring, and evaluation of AI systems.\n",
      "3. **Human oversight and review**: Implementing human oversight and review processes can help ensure accountability in autonomous AI decision-making. For example, autonomous vehicles may require human intervention if a critical decision is made that has significant safety implications.\n",
      "4. **Value alignment**: Ensuring that AI systems are designed to align with human values, such as the value of preserving human life, is crucial. This could involve programming AI systems with ethical principles and ensuring that they are configured to prioritize human safety above other goals.\n",
      "5. **Redundancy and fail-safes**: Incorporating redundancy and fail-safes into autonomous AI systems can help prevent harm in situations where decisions need to be made quickly. For example, two separate critical processes could be designed to require human override before proceeding with potentially life-threatening actions.\n",
      "6. **Regulatory oversight**: Governments and regulatory bodies should establish clear guidelines, standards, and regulations for the development, deployment, and operation of autonomous AI systems. This can help ensure accountability and provide a framework for evaluating safety and ethical performance.\n",
      "7. **Continuous learning and improvement**: Autonomous AI systems should be designed to continuously learn from their experiences, adapt to new situations, and improve over time. This can involve incorporating data from various sources, including human feedback, to refine decision-making algorithms.\n",
      "8. **Robust testing and validation**: Thorough testing and validation of autonomous AI systems are essential to ensure their accuracy, reliability, and safety. This could involve simulations, real-time monitoring, and comprehensive documentation of the system's performance.\n",
      "9. **Transparency in data collection and use**: Ensuring that data used for training and decision-making is transparent, accurate, and unbiased can help maintain accountability. This includes providing insights into how AI systems make decisions and identifying any potential biases or flaws.\n",
      "10. **Ethical guidelines and principles**: Establishing clear ethical guidelines and principles for the development of autonomous AI systems can provide a shared framework for understanding what it means to prioritize human well-being, safety, and values.\n",
      "\n",
      "Ultimately, reconciling the ethical implications of autonomous AI decision-making requires a multi-faceted approach that combines technical innovation with social responsibility. By prioritizing transparency, accountability, and human oversight, we can ensure that these systems are developed and deployed in ways that respect human dignity and promote the greater good.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"3\", \"1\", \"4\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: llama3.2\n",
      "Rank 4: gpt-3.5-turbo-1106\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
